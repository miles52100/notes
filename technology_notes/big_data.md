# Big Data Storage 

Technologies for big data storage

## File formats, SQL queries and Analytics Tech

### Parquet file format
Apache Parquet is an open source, column-oriented data file format designed for efficient data storage and retrieval.

Designed to be a common interchange format for both batch and interactive workloads.

For more details see [here](https://www.databricks.com/glossary/what-is-parquet)

Column based storage brings more efficiencies than row based such as CSV

### Trino

A **distributed** SQL query engine that runs very fast, designed for big data analytics.
See [here](https://trino.io/)


### Athena

**Amazon Athena** interactive query service that makes it easy to analyze data in S3 buckets using standard SQL.

See [here](https://docs.aws.amazon.com/whitepapers/latest/big-data-analytics-options/amazon-athena.html)

### RAPIDs

RAPIDS had its start from the Apache Arrow and GoAi projects based on a columnar, in-memory data structure that delivers efficient and fast data interchange with flexibility to support complex data models.

See [here](https://rapids.ai/)

Utilizing NVIDIA CUDA primitives for low-level compute optimization, RAPIDS exposes GPU parallelism and high-bandwidth memory speed through user-friendly interfaces:


## Large-scale graphs Tech

### Neo4j
### Raphtory
### PyG
### GraphFrames
### GraphMT






